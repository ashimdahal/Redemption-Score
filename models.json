[
    {
        "processor_name": "Salesforce/blip-image-captioning-base",
        "decoder_class": "BlipForConditionalGeneration",
        "decoder_name": "Salesforce/blip-image-captioning-base",
        "requires_original": true,
        "adapter_hub_id": "ashimdahal/Salesforce-blip-image-captioning-base_Salesforce-blip-image-captioning-base"
    },
    {
        "processor_name": "Salesforce/blip2-opt-2.7b",
        "decoder_class": "Blip2ForConditionalGeneration",
        "decoder_name": "Salesforce/blip2-opt-2.7b",
        "requires_original": true,
        "adapter_hub_id": "ashimdahal/Salesforce-blip2-opt-2.7b_Salesforce-blip2-opt-2.7b"
    },
    {
        "processor_name": "microsoft/git-base",
        "decoder_class": "AutoModelForCausalLM",
        "decoder_name": "microsoft/git-base",
        "tokenizer_name": "microsoft/git-base",
        "adapter_hub_id": "ashimdahal/microsoft-git-base_microsoft-git-base"
    },
    {
        "processor_name": "nlpconnect/vit-gpt2-image-captioning",
        "decoder_class": "VisionEncoderDecoderModel",
        "decoder_name": "nlpconnect/vit-gpt2-image-captioning",
        "processor_class": "ViTImageProcessor",
        "adapter_hub_id": "ashimdahal/nlpconnect-vit-gpt2-image-captioning_nlpconnect-vit-gpt2-image-captioning"
    },
    {
        "processor_name": "Ertugrul/Qwen2-VL-7B-Captioner-Relaxed",
        "decoder_class": "Qwen2VLForConditionalGeneration",
        "decoder_name": "Ertugrul/Qwen2-VL-7B-Captioner-Relaxed",
        "adapter_hub_id": "ashimdahal/Ertugrul-Qwen2-VL-7B-Captioner-Relaxed_Qwen-Qwen2-VL-7B-Instruct"
    }
]
